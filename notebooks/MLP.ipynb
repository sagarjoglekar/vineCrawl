{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "from load import faces\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "currentDir =  os.getcwd();\n",
    "parampickle = currentDir + \"/parametersMLP.pickle\"\n",
    "costPickle = currentDir + \"/costPickleMLP.pickle\"\n",
    "errorPickle = currentDir + \"/errorPickleMLP.pickle\"\n",
    "logFile = currentDir + \"/logFileMLP.log\"\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01) , borrow=True )\n",
    "\n",
    "def init_biases(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01) , borrow=True )\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X * srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X = (X/retain_prob)\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "\n",
    "def model(X, w1, w2, w3, w4, w5, b5 , w6 ,b6 , w_o, p_drop_conv, p_drop_hidden):\n",
    "    \n",
    "    l1 = rectify(conv2d(X, w1, border_mode='full'))\n",
    "\n",
    "    l2a = rectify(conv2d(l1, w2))\n",
    "    l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2, p_drop_conv)\n",
    "    \n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    l3 = max_pool_2d(l3a, (2, 2))\n",
    "    \n",
    "    l4a = rectify(conv2d(l3,w4))\n",
    "    l4b = max_pool_2d(l4a, (2, 2))\n",
    "    l4c = T.flatten(l4b, outdim=2)\n",
    "    l4 = dropout(l4c, p_drop_conv)\n",
    "\n",
    "    l5a = T.dot(l4, w5) + b5\n",
    "    l5 = T.nnet.sigmoid(l5a)\n",
    "    \n",
    "    l6a = T.dot(l5, w6) + b6\n",
    "    l6 = T.nnet.sigmoid(l6a)\n",
    "\n",
    "    pyx = softmax(T.dot(l6, w_o))\n",
    "    \n",
    "    return l1, l2, l3, l4, l5, l6, pyx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = faces()\n",
    "trX = trX.reshape(-1, 1, 48, 48)\n",
    "teX = teX.reshape(-1, 1, 48, 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize All the parameters\n",
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "w1 = init_weights((32, 1, 11, 11))\n",
    "\n",
    "w2 = init_weights((64, 32, 7, 7))\n",
    "\n",
    "w3 = init_weights((128, 64, 5, 5))\n",
    "\n",
    "w4 = init_weights((128, 128, 3, 3))\n",
    "\n",
    "w5 = init_weights((128 * 5 * 5 , 100))\n",
    "b5 = init_biases((32,100))\n",
    "\n",
    "w6 = init_weights((100 , 100))\n",
    "b6 = init_biases((32,100))\n",
    "\n",
    "w_o = init_weights((100, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Loop\n",
    "noise_l1, noise_l2, noise_l3, noise_l4, noise_l5, noise_l6, noise_py_x = model(X, w1, w2, w3, w4, w5, b5, w6, b6, w_o, 0.2, 0.5)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w1, w2, w3, w4, w5 ,b5 ,w6 , b6, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.009)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "#Predict Loop\n",
    "l1, l2, l3, l4, l5, l6 , py_x = model(X, w1, w2, w3, w4, w5, b5, w6, b6, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    for start, end in zip(range(0 ,len(trX) ,32), range(32 ,len(trX) ,32)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    logline = \"Interation number: \" + str(i) + \", Cost value : \" + str(cost)\n",
    "    \n",
    "    print \"Interation number: \" + str(i)\n",
    "    print \"Cost value : \" + str(cost)\n",
    "    \n",
    "    f = open(costPickle, 'a+')\n",
    "    f2 = open(logFile, 'a+')\n",
    "    \n",
    "    pickle.dump(logline, f)\n",
    "    f2.write(logline)\n",
    "    \n",
    "    f.close()\n",
    "    f2.close()\n",
    "    \n",
    "    if i%100 == 0 :\n",
    "        for start, end in zip(range(0, len(teX),32), range(32, len(teX),32)):\n",
    "            error = np.mean(np.argmax(teY[start:end], axis=1) == predict(teX[start:end]))\n",
    "            logline = \"Error = \" + str(error)\n",
    "    \n",
    "            print error\n",
    "    \n",
    "            f = open(errorPickle, 'a+')\n",
    "            f2 = open(logFile, 'a+')\n",
    "    \n",
    "            pickle.dump(logline, f)\n",
    "            f2.write(logline)\n",
    "    \n",
    "            f.close()\n",
    "            f2.close()\n",
    "\n",
    "f3 = open(parampickle,'a+')\n",
    "pickle.dump(params, f3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
