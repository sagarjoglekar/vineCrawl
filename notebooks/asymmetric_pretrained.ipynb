{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../lib\")\n",
    "from load import getValData\n",
    "from load import faces\n",
    "import pickle\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "from six.moves import cPickle\n",
    "from numpy import genfromtxt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = faces(onehot=True)\n",
    "trX = trX.reshape(-1, 1, 48, 48)\n",
    "teX = teX.reshape(-1, 1, 48, 48)\n",
    "ValX = genfromtxt('../CKPlus/CKfaces.csv', delimiter=',')\n",
    "ValX = ValX.reshape(-1, 1, 48, 48)\n",
    "ValY = genfromtxt('../CKPlus/labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    W = theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "    return W\n",
    "\n",
    "def init_bias(shape):\n",
    "    b_values = np.zeros((shape[0],), dtype=theano.config.floatX)\n",
    "    b = theano.shared(value=b_values, borrow=True )\n",
    "    return b\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X *  srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X = (X/retain_prob)\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def negative_log_likelihood(p_y_given_x,y):\n",
    "        \"\"\"Return the mean of the negative log-likelihood of the prediction\n",
    "        of this model under a given target distribution.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n",
    "            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n",
    "                \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) \\\\\n",
    "            \\ell (\\theta=\\{W,b\\}, \\mathcal{D})\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "\n",
    "        Note: we use the mean instead of the sum so that\n",
    "              the learning rate is less dependent on the batch size\n",
    "        \"\"\"\n",
    "        # start-snippet-2\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of examples (call it n) in the minibatch\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model1(X, w, b , w2, b2 ,  w3, b3, w4, b4, w5 , b5, w6 , b6 , w_o, b_o, p_drop_conv, p_drop_hidden):\n",
    "    l1a = conv2d(X, w)\n",
    "    l1a = rectify(l1a + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = conv2d(l1, w2)\n",
    "    l2a = rectify(l2a + b2.dimshuffle('x', 0, 'x', 'x'))\n",
    "    #l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2a, p_drop_conv)\n",
    "    \n",
    "    l3a = conv2d(l2, w3)\n",
    "    l3a = rectify(l3a + b3.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l3 = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4a = conv2d(l3, w4)\n",
    "    l4b = rectify(l4a + b4.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l4 = T.flatten(l4b, outdim=2)\n",
    "    l4 = dropout(l4, p_drop_conv)\n",
    "\n",
    "    l5 = rectify(T.dot(l4, w5) + b5.dimshuffle('x', 0 ))\n",
    "    l5 = dropout(l5, p_drop_hidden)\n",
    "    \n",
    "    l6 = rectify(T.dot(l5, w6) + b6.dimshuffle('x', 0))\n",
    "    l6 = dropout(l6, p_drop_hidden)\n",
    "\n",
    "    # Add numerically stable softmax\n",
    "    pyx = T.nnet.softmax(T.dot(l6, w_o) + b_o.dimshuffle('x', 0))\n",
    "    #opVec = T.dot(l6, w_o) + b_o.dimshuffle('x', 0)\n",
    "    #xdev = opVec-opVec.max(1,keepdims=True)\n",
    "    #pyx = xdev - T.log(T.sum(T.exp(xdev),axis=1,keepdims=True))\n",
    "    return l1, l2, l3, l4, l5, l6, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model2(X, w, b , w2, b2 ,w3, b3 , w4 , b4, w5, b5 , w_o, b_o, p_drop_conv, p_drop_hidden):\n",
    "    l1a = conv2d(X, w)\n",
    "    l1a = rectify(l1a + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = conv2d(l1, w2)\n",
    "    l2a = rectify(l2a + b2.dimshuffle('x', 0, 'x', 'x'))\n",
    "    #l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2a, p_drop_conv)\n",
    "    \n",
    "    l3a = conv2d(l2, w3)\n",
    "    l3a = rectify(l3a + b3.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l3 = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4_input = T.flatten(l3, outdim=2)\n",
    "    l4 = rectify(T.dot(l4_input, w4) + b4.dimshuffle('x', 0 ))\n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "    \n",
    "    l5 = rectify(T.dot(l4, w5) + b5.dimshuffle('x', 0 ))\n",
    "\n",
    "    l6a = T.dot(l5, w_o) + b_o.dimshuffle('x', 0)\n",
    "    ydev = l6a-l6a.max(1,keepdims=True)\n",
    "    pyx = ydev - T.log(T.sum(T.exp(ydev),axis=1,keepdims=True))\n",
    "    return l1, l2, l3, l4, l5, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict Loop\n",
    "model1Params = open(\"ModelsV1/ModelSnapshot1000.pkl\")\n",
    "Params1 = cPickle.load(model1Params)\n",
    "\n",
    "model2Params = open(\"Models5LayersV2/ModelSnapshot1999.pkl\")\n",
    "Params2 = cPickle.load(model2Params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "l11, l12, l13, l14, l15,l16, py_x1 = model1(X, Params1[0], Params1[1], Params1[2], Params1[3], Params1[4], Params1[5], Params1[6], Params1[7], Params1[8], Params1[9], Params1[10], Params1[11], Params1[12], Params1[13], 0., 0.)\n",
    "l21, l22, l23, l24, l25, py_x2 = model2(X, Params2[0], Params2[1], Params2[2], Params2[3], Params2[4], Params2[5], Params2[6], Params2[7], Params2[8], Params2[9], Params2[10], Params2[11], 0., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op1dist = theano.function(inputs=[X], outputs=py_x1, allow_input_downcast=True)\n",
    "\n",
    "op2dist = theano.function(inputs=[X], outputs=py_x2, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pyTe1 = op1dist(teX)\n",
    "# pyTe2 = op2dist(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# error = np.mean(np.argmax(teY, axis=1) == np.argmax(pyTe2, axis=1))\n",
    "# print error\n",
    "\n",
    "# error = np.mean(np.argmax(teY, axis=1) == np.argmax(pyTe1, axis=1))\n",
    "# print error               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 14)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "compound_train = np.zeros((len(trX),14))\n",
    "for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX), batch_size)):\n",
    "    pyTr1 = op1dist(trX[start:end])\n",
    "    pyTr2 = op2dist(trX[start:end])\n",
    "    compound_train[start:end] = np.concatenate((pyTr1,pyTr2 ), axis=1)\n",
    "print compound_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(n_estimators=14)\n",
    "labels = np.argmax(trY, axis=1)\n",
    "clfRF.fit(compound_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyTe1 = op1dist(teX)\n",
    "pyTe2 = op2dist(teX)\n",
    "compound_test = np.concatenate((pyTe1,pyTe2 ), axis=1)\n",
    "RF_predict = clfRF.predict(compound_test)\n",
    "error_RF = np.mean(np.argmax(teY, axis=1) == RF_predict )\n",
    "print error_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pyTe1 , pyTe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574923547401\n"
     ]
    }
   ],
   "source": [
    "pyTe1 = op1dist(ValX)\n",
    "pyTe2 = op2dist(ValX)\n",
    "compound_test = np.concatenate((pyTe1,pyTe2 ), axis=1)\n",
    "RF_predict = clfRF.predict(compound_test)\n",
    "error_RF = np.mean(np.argmax(ValY, axis=1) == RF_predict )\n",
    "print error_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559633027523\n",
      "0.581039755352\n"
     ]
    }
   ],
   "source": [
    "print np.mean(np.argmax(ValY, axis=1) == np.argmax(pyTe1, axis=1) )\n",
    "print np.mean(np.argmax(ValY, axis=1) == np.argmax(pyTe2, axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07856726  0.00658807  0.07284225  0.13340585  0.11599172  0.03306238\n",
      "  0.11714295  0.07299661  0.01154338  0.04140623  0.09673813  0.06888963\n",
      "  0.06298945  0.08783609]\n"
     ]
    }
   ],
   "source": [
    "print clfRF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.   0.   2.   0.  18.   1.  11.]\n",
      " [ 39.   7.   0.   5.   9.   0.  17.]\n",
      " [  0.   2.   3.   6.   7.   2.   5.]\n",
      " [  0.   0.   1.  68.   0.   0.   0.]\n",
      " [  4.   1.   1.   0.  19.   0.   3.]\n",
      " [  0.   0.   1.   2.   1.  78.   1.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "Precision: \n",
      "0.288888888889\n",
      "0.0909090909091\n",
      "0.12\n",
      "0.985507246377\n",
      "0.678571428571\n",
      "0.939759036145\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real = np.argmax(ValY, axis=1)\n",
    "confusion = np.zeros((7,7))\n",
    "for i in range(0 , len(real)):\n",
    "    j = real[i]\n",
    "    k = RF_predict[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1\n",
    "print confusion\n",
    "print \"Precision: \"\n",
    "for j in range(0,7):\n",
    "    print (confusion[j][j]/sum(confusion[:][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSFT API ANALISYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('../Logs/MsftTestScores.pkl', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()\n",
    "\n",
    "MSFTTeFer = np.zeros((len(lists),7))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(',')\n",
    "    for j in range(0,7):\n",
    "        MSFTTeFer[i][j]=float(log[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('../Logs//MsftTrainScores.pkl', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()\n",
    "\n",
    "MSFTTrFer = np.zeros((len(lists),7))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(',')\n",
    "    for j in range(0,7):\n",
    "        MSFTTrFer[i][j]=float(log[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('../Logs/MsftTestScoresCKplus.pkl', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()\n",
    "\n",
    "MSFTValCKplus = np.zeros((len(lists),7))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(',')\n",
    "    for j in range(0,7):\n",
    "        MSFTValCKplus[i][j]=float(log[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n",
      "(1402, 7)\n",
      "(327, 7)\n"
     ]
    }
   ],
   "source": [
    "print MSFTTeFer.shape\n",
    "print MSFTTrFer.shape\n",
    "print MSFTValCKplus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n",
      "0.558372805795\n"
     ]
    }
   ],
   "source": [
    "print MSFTTeFer.shape\n",
    "\n",
    "A = np.argmax(teY, axis=1)\n",
    "B = np.argmax(MSFTTeFer, axis=1)\n",
    "print np.mean(A == B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 7)\n",
      "0.691131498471\n",
      "[[  9.   0.   0.   0.   0.   0.  36.]\n",
      " [  6.  46.   0.   9.   0.   0.  16.]\n",
      " [  0.   3.   9.   5.   6.   2.   0.]\n",
      " [  1.   0.   0.  68.   0.   0.   0.]\n",
      " [  1.   0.   0.   0.  16.   0.  11.]\n",
      " [  1.   0.   0.   1.   0.  78.   3.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "Precision: \n",
      "0.2\n",
      "0.597402597403\n",
      "0.36\n",
      "0.985507246377\n",
      "0.571428571429\n",
      "0.939759036145\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print MSFTValCKplus.shape\n",
    "\n",
    "A = np.argmax(ValY, axis=1)\n",
    "B = np.argmax(MSFTValCKplus, axis=1)\n",
    "print np.mean(A == B)\n",
    "real = np.argmax(ValY, axis=1)\n",
    "confusion = np.zeros((7,7))\n",
    "for i in range(0 , len(real)):\n",
    "    j = real[i]\n",
    "    k = B[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1\n",
    "print confusion\n",
    "print \"Precision: \"\n",
    "for j in range(0,7):\n",
    "    print (confusion[j][j]/sum(confusion[j][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1402, 7)\n",
      "0.5485021398\n"
     ]
    }
   ],
   "source": [
    "print MSFTTrFer.shape\n",
    "\n",
    "A = np.argmax(trY[:len(MSFTTrFer)], axis=1)\n",
    "B = np.argmax(MSFTTrFer, axis=1)\n",
    "print np.mean(A == B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
