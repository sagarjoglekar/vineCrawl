{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import timeit\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import os\n",
    "try:\n",
    "    import PIL.Image as Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "    \n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../lib\")\n",
    "from load import mnist\n",
    "from load import faces\n",
    "from rbm import RBM\n",
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY  = faces(onehot=False)\n",
    "#trX, teX, trY, teY  = mnist(onehot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x = theano.shared(numpy.asarray(trX, dtype=theano.config.floatX),borrow=True)\n",
    "test_set_x = theano.shared(numpy.asarray(teX, dtype=theano.config.floatX),borrow=True)\n",
    "train_set_y = theano.shared(numpy.asarray(trY, dtype=\"int32\"),borrow=True)\n",
    "test_set_y = theano.shared(numpy.asarray(teY, dtype=\"int32\"),borrow=True)\n",
    "\n",
    "datasets = [(train_set_x, train_set_y),(test_set_x, test_set_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_rbm(dataset,learning_rate=0.005, training_epochs=10,\n",
    "             batch_size=14,\n",
    "             n_chains=14, n_samples=7, output_folder='rbm_plots_FER',\n",
    "             n_hidden=1400):\n",
    "    \"\"\"\n",
    "    Demonstrate how to train and afterwards sample from it using Theano.\n",
    "\n",
    "    This is demonstrated on MNIST.\n",
    "\n",
    "    :param learning_rate: learning rate used for training the RBM\n",
    "\n",
    "    :param training_epochs: number of epochs used for training\n",
    "\n",
    "    :param dataset: path the the pickled dataset\n",
    "\n",
    "    :param batch_size: size of a batch used to train the RBM\n",
    "\n",
    "    :param n_chains: number of parallel Gibbs chains to be used for sampling\n",
    "\n",
    "    :param n_samples: number of samples to plot for each chain\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    train_set_x = dataset[0][0]\n",
    "    test_set_x = dataset[1][0]\n",
    "    train_set_y = dataset[0][1]\n",
    "    test_set_y = dataset[1][1]\n",
    "    \n",
    "    print train_set_x.shape\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    print str(n_train_batches)\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()    # index to a [mini]batch\n",
    "    x = T.matrix('x')  # the data is presented as rasterized images\n",
    "\n",
    "    rng = numpy.random.RandomState(123)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "    # initialize storage for the persistent chain (state = hidden\n",
    "    # layer of chain)\n",
    "    persistent_chain = theano.shared(numpy.zeros((batch_size, n_hidden),\n",
    "                                                 dtype=theano.config.floatX),\n",
    "                                     borrow=True)\n",
    "\n",
    "    # construct the RBM class\n",
    "    rbm = RBM(input=x, n_visible=48 * 48,\n",
    "              n_hidden=n_hidden, numpy_rng=rng, theano_rng=theano_rng)\n",
    "\n",
    "    # get the cost and the gradient corresponding to one step of CD-15\n",
    "    cost, updates = rbm.get_cost_updates(lr=learning_rate,\n",
    "                                         persistent=persistent_chain, k=15)\n",
    "\n",
    "    #################################\n",
    "    #     Training the RBM          #\n",
    "    #################################\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    os.chdir(output_folder)\n",
    "\n",
    "    # start-snippet-5\n",
    "    # it is ok for a theano function to have no output\n",
    "    # the purpose of train_rbm is solely to update the RBM parameters\n",
    "    print str(index * batch_size)\n",
    "    \n",
    "    train_rbm = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        },\n",
    "        name='train_rbm'\n",
    "    )\n",
    "\n",
    "    plotting_time = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # go through training epochs\n",
    "    for epoch in xrange(training_epochs):\n",
    "\n",
    "        # go through the training set\n",
    "        mean_cost = []\n",
    "        for batch_index in xrange(n_train_batches):\n",
    "            mean_cost += [train_rbm(batch_index)]\n",
    "\n",
    "        print 'Training epoch %d, cost is ' % epoch, numpy.mean(mean_cost)\n",
    "\n",
    "        # Plot filters after each training epoch\n",
    "        plotting_start = timeit.default_timer()\n",
    "        # Construct image from the weight matrix\n",
    "        image = Image.fromarray(\n",
    "            tile_raster_images(\n",
    "                X=rbm.W.get_value(borrow=True).T,\n",
    "                img_shape=(48, 48),\n",
    "                tile_shape=(10, 10),\n",
    "                tile_spacing=(1, 1)\n",
    "            )\n",
    "        )\n",
    "        image.save('filters_at_epoch_%i.png' % epoch)\n",
    "        plotting_stop = timeit.default_timer()\n",
    "        plotting_time += (plotting_stop - plotting_start)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    pretraining_time = (end_time - start_time) - plotting_time\n",
    "\n",
    "    print ('Training took %f minutes' % (pretraining_time / 60.))\n",
    "    # end-snippet-5 start-snippet-6\n",
    "    #################################\n",
    "    #     Sampling from the RBM     #\n",
    "    #################################\n",
    "    # find out the number of test samples\n",
    "    number_of_test_samples = test_set_x.get_value(borrow=True).shape[0]\n",
    "\n",
    "    # pick random test examples, with which to initialize the persistent chain\n",
    "    test_idx = rng.randint(number_of_test_samples - n_chains)\n",
    "    persistent_vis_chain = theano.shared(\n",
    "        numpy.asarray(\n",
    "            test_set_x.get_value(borrow=True)[test_idx:test_idx + n_chains],\n",
    "            dtype=theano.config.floatX\n",
    "        )\n",
    "    )\n",
    "    # end-snippet-6 start-snippet-7\n",
    "    plot_every = 1000\n",
    "    # define one step of Gibbs sampling (mf = mean-field) define a\n",
    "    # function that does `plot_every` steps before returning the\n",
    "    # sample for plotting\n",
    "    (\n",
    "        [\n",
    "            presig_hids,\n",
    "            hid_mfs,\n",
    "            hid_samples,\n",
    "            presig_vis,\n",
    "            vis_mfs,\n",
    "            vis_samples\n",
    "        ],\n",
    "        updates\n",
    "    ) = theano.scan(\n",
    "        rbm.gibbs_vhv,\n",
    "        outputs_info=[None, None, None, None, None, persistent_vis_chain],\n",
    "        n_steps=plot_every\n",
    "    )\n",
    "\n",
    "    # add to updates the shared variable that takes care of our persistent\n",
    "    # chain :.\n",
    "    updates.update({persistent_vis_chain: vis_samples[-1]})\n",
    "    # construct the function that implements our persistent chain.\n",
    "    # we generate the \"mean field\" activations for plotting and the actual\n",
    "    # samples for reinitializing the state of our persistent chain\n",
    "    sample_fn = theano.function(\n",
    "        [],\n",
    "        [\n",
    "            vis_mfs[-1],\n",
    "            vis_samples[-1]\n",
    "        ],\n",
    "        updates=updates,\n",
    "        name='sample_fn'\n",
    "    )\n",
    "\n",
    "    # create a space to store the image for plotting ( we need to leave\n",
    "    # room for the tile_spacing as well)\n",
    "    image_data = numpy.zeros(\n",
    "        (29 * n_samples + 1, 29 * n_chains - 1),\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    for idx in xrange(n_samples):\n",
    "        # generate `plot_every` intermediate samples that we discard,\n",
    "        # because successive samples in the chain are too correlated\n",
    "        vis_mf, vis_sample = sample_fn()\n",
    "        print ' ... plotting sample ', idx\n",
    "        image_data[49 * idx:49 * idx + 48, :] = tile_raster_images(\n",
    "            X=vis_mf,\n",
    "            img_shape=(48, 48),\n",
    "            tile_shape=(1, n_chains),\n",
    "            tile_spacing=(1, 1)\n",
    "        )\n",
    "\n",
    "    # construct image\n",
    "    image = Image.fromarray(image_data)\n",
    "    image.save('samples.png')\n",
    "    # end-snippet-7\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape.0\n",
      "2050\n",
      "Elemwise{mul,no_inplace}.0\n",
      "Training epoch 0, cost is  -1.13252e+07\n",
      "Training epoch 1, cost is  -3.61015e+07\n",
      "Training epoch 2, cost is  -6.01769e+07\n",
      "Training epoch 3, cost is  -8.87028e+07\n",
      "Training epoch 4, cost is  -1.178e+08\n",
      "Training epoch 5, cost is  -1.63161e+08\n",
      "Training epoch 6, cost is  -1.8538e+08\n",
      "Training epoch 7, cost is  -2.14662e+08\n",
      "Training epoch 8, cost is  -2.55963e+08\n",
      "Training epoch 9, cost is  -2.45663e+08\n",
      "Training took 10.696327 minutes\n",
      " ... plotting sample  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (48,685) into shape (48,405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ed56cff7c534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_rbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-54d693a7e181>\u001b[0m in \u001b[0;36mtest_rbm\u001b[1;34m(dataset, learning_rate, training_epochs, batch_size, n_chains, n_samples, output_folder, n_hidden)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mimg_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mtile_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_chains\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mtile_spacing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         )\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (48,685) into shape (48,405)"
     ]
    }
   ],
   "source": [
    "test_rbm(dataset=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
