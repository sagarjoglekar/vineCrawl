{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../lib\")\n",
    "from load import mnist\n",
    "from load import faces\n",
    "import pickle\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "import theano.misc.pkl_utils.dump as dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentDir =  os.getcwd();\n",
    "parampickle = currentDir + \"/parametersConvonet.pickle\"\n",
    "logPickle = currentDir + \"/logPickleDBN.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X *  srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X = (X/retain_prob)\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(X, w, w2, w3, w4, w5 , w6 ,w_o, p_drop_conv, p_drop_hidden):\n",
    "    l1a = rectify(conv2d(X, w, border_mode='full'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = rectify(conv2d(l1, w2))\n",
    "    l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2, p_drop_conv)\n",
    "    \n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    l3 = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4a = rectify(conv2d(l3, w4))\n",
    "    l4 = T.flatten(l4a, outdim=2)\n",
    "    l4 = dropout(l4, p_drop_conv)\n",
    "\n",
    "    l5 = rectify(T.dot(l4, w5))\n",
    "    l5 = dropout(l5, p_drop_hidden)\n",
    "    \n",
    "    l6 = rectify(T.dot(l5, w6))\n",
    "    l6 = dropout(l6, p_drop_hidden)\n",
    "\n",
    "    pyx = softmax(T.dot(l6, w_o))\n",
    "    return l1, l2, l3, l4, l5, l6, pyx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trX, teX, trY, teY = mnist(onehot=True)\n",
    "trX, teX, trY, teY = faces(onehot=True)\n",
    "\n",
    "trX = trX.reshape(-1, 1, 48, 48)\n",
    "teX = teX.reshape(-1, 1, 48, 48)\n",
    "\n",
    "#trX = numpy.asarray(trX, dtype=theano.config.floatX)\n",
    "#teX = teX.reshape(-1, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((32, 1, 7, 7))\n",
    "w2 = init_weights((64, 32, 5, 5))\n",
    "w3 = init_weights((128, 64, 3, 3))\n",
    "w4 = init_weights((256, 128, 3, 3))\n",
    "w5 = init_weights((256 * 3 * 3, 10000)) \n",
    "w6 = init_weights((10000, 1000)) \n",
    "w_o = init_weights((1000, 7))\n",
    "\n",
    "#Train Loop\n",
    "noise_l1, noise_l2, noise_l3, noise_l4, noise_l5 , noise_l6, noise_py_x = model(X, w, w2, w3, w4, w5, w6, w_o, 0.2, 0.5)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w, w2, w3, w4, w5, w6, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.0009)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#Predict Loop\n",
    "l1, l2, l3, l4, l5,l6, py_x = model(X, w, w2, w3, w4, w5, w6, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Error: 0.249651713569\n",
      "Epoch: 1  Error: 0.249651713569\n",
      "Epoch: 2  Error: 0.332961827807\n",
      "Epoch: 3  Error: 0.398161047646\n",
      "Epoch: 4  Error: 0.41961549178\n",
      "Epoch: 5  Error: 0.441905823349\n",
      "Epoch: 6  Error: 0.449150181109\n",
      "Epoch: 7  Error: 0.491780440234\n",
      "Epoch: 8  Error: 0.485929228197\n",
      "Epoch: 9  Error: 0.491780440234\n",
      "Epoch: 10  Error: 0.502089718585\n",
      "Epoch: 11  Error: 0.515463917526\n",
      "Epoch: 12  Error: 0.530509891335\n",
      "Epoch: 13  Error: 0.53747561995\n",
      "Epoch: 14  Error: 0.53385344107\n",
      "Epoch: 15  Error: 0.515463917526\n",
      "Epoch: 16  Error: 0.539426023962\n",
      "Epoch: 17  Error: 0.545834494288\n",
      "Epoch: 18  Error: 0.543605461131\n",
      "Epoch: 19  Error: 0.545834494288\n",
      "Epoch: 20  Error: 0.542212315408\n",
      "Epoch: 21  Error: 0.541655057119\n",
      "Epoch: 22  Error: 0.549178044023\n",
      "Epoch: 23  Error: 0.555307885205\n",
      "Epoch: 24  Error: 0.537754249094\n",
      "Epoch: 25  Error: 0.563388130398\n",
      "Epoch: 26  Error: 0.545834494288\n",
      "Epoch: 27  Error: 0.54834215659\n",
      "Epoch: 28  Error: 0.549178044023\n",
      "Epoch: 29  Error: 0.549178044023\n",
      "Epoch: 30  Error: 0.565617163555\n",
      "Epoch: 31  Error: 0.551685706325\n",
      "Epoch: 32  Error: 0.555586514349\n",
      "Epoch: 33  Error: 0.564224017832\n",
      "Epoch: 34  Error: 0.555865143494\n",
      "Epoch: 35  Error: 0.560601838952\n",
      "Epoch: 36  Error: 0.550013931457\n",
      "Epoch: 37  Error: 0.560044580663\n",
      "Epoch: 38  Error: 0.556979660072\n",
      "Epoch: 39  Error: 0.55865143494\n",
      "Epoch: 40  Error: 0.550571189746\n",
      "Epoch: 41  Error: 0.551964335469\n",
      "Epoch: 42  Error: 0.551964335469\n",
      "Epoch: 43  Error: 0.5658957927\n",
      "Epoch: 44  Error: 0.547506269156\n",
      "Epoch: 45  Error: 0.549735302313\n",
      "Epoch: 46  Error: 0.561716355531\n",
      "Epoch: 47  Error: 0.554471997771\n",
      "Epoch: 48  Error: 0.552521593759\n",
      "Epoch: 49  Error: 0.56227361382\n",
      "Epoch: 50  Error: 0.537196990805\n",
      "Epoch: 51  Error: 0.564781276121\n",
      "Epoch: 52  Error: 0.564224017832\n",
      "Epoch: 53  Error: 0.5658957927\n",
      "Epoch: 54  Error: 0.557815547506\n",
      "Epoch: 55  Error: 0.542212315408\n",
      "Epoch: 56  Error: 0.55140707718\n",
      "Epoch: 57  Error: 0.558094176651\n",
      "Epoch: 58  Error: 0.539704653107\n",
      "Epoch: 59  Error: 0.560880468097\n",
      "Epoch: 60  Error: 0.551128448036\n",
      "Epoch: 61  Error: 0.556979660072\n",
      "Epoch: 62  Error: 0.553078852048\n",
      "Epoch: 63  Error: 0.557536918362\n",
      "Epoch: 64  Error: 0.571189746447\n",
      "Epoch: 65  Error: 0.563666759543\n",
      "Epoch: 66  Error: 0.552800222903\n",
      "Epoch: 67  Error: 0.551685706325\n",
      "Epoch: 68  Error: 0.555586514349\n",
      "Epoch: 69  Error: 0.556143772639\n",
      "Epoch: 70  Error: 0.566174421845\n",
      "Epoch: 71  Error: 0.524380050153\n",
      "Epoch: 72  Error: 0.548899414879\n",
      "Epoch: 73  Error: 0.560601838952\n",
      "Epoch: 74  Error: 0.539983282251\n",
      "Epoch: 75  Error: 0.553636110337\n",
      "Epoch: 76  Error: 0.55865143494\n",
      "Epoch: 77  Error: 0.532181666202\n",
      "Epoch: 78  Error: 0.570075229869\n",
      "Epoch: 79  Error: 0.551685706325\n",
      "Epoch: 80  Error: 0.560880468097\n",
      "Epoch: 81  Error: 0.560044580663\n",
      "Epoch: 82  Error: 0.557536918362\n",
      "Epoch: 83  Error: 0.557815547506\n",
      "Epoch: 84  Error: 0.480913903594\n",
      "Epoch: 85  Error: 0.576483700195\n",
      "Epoch: 86  Error: 0.553357481193\n",
      "Epoch: 87  Error: 0.553357481193\n",
      "Epoch: 88  Error: 0.556701030928\n",
      "Epoch: 89  Error: 0.545834494288\n",
      "Epoch: 90  Error: 0.552800222903\n",
      "Epoch: 91  Error: 0.555865143494\n",
      "Epoch: 92  Error: 0.540819169685\n",
      "Epoch: 93  Error: 0.566731680134\n",
      "Epoch: 94  Error: 0.566731680134\n",
      "Epoch: 95  Error: 0.566453050989\n",
      "Epoch: 96  Error: 0.535803845082\n",
      "Epoch: 97  Error: 0.550571189746\n",
      "Epoch: 98  Error: 0.517971579827\n",
      "Epoch: 99  Error: 0.551128448036\n",
      "Epoch: 100  Error: 0.559765951519\n",
      "Epoch: 101  Error: 0.560044580663\n",
      "Epoch: 102  Error: 0.562552242965\n",
      "Epoch: 103  Error: 0.551685706325\n",
      "Epoch: 104  Error: 0.574533296183\n",
      "Epoch: 105  Error: 0.40930621343\n",
      "Epoch: 106  Error: 0.523544162719\n",
      "Epoch: 107  Error: 0.558930064085\n",
      "Epoch: 108  Error: 0.554193368626\n",
      "Epoch: 109  Error: 0.546670381722\n",
      "Epoch: 110  Error: 0.526887712455\n",
      "Epoch: 111  Error: 0.566731680134\n",
      "Epoch: 112  Error: 0.551964335469\n",
      "Epoch: 113  Error: 0.54834215659\n",
      "Epoch: 114  Error: 0.552521593759\n",
      "Epoch: 115  Error: 0.550849818891\n",
      "Epoch: 116  Error: 0.535246586793\n",
      "Epoch: 117  Error: 0.568403455001\n",
      "Epoch: 118  Error: 0.555586514349\n",
      "Epoch: 119  Error: 0.551685706325\n",
      "Epoch: 120  Error: 0.556422401783\n",
      "Epoch: 121  Error: 0.572861521315\n",
      "Epoch: 122  Error: 0.561994984675\n",
      "Epoch: 123  Error: 0.554193368626\n",
      "Epoch: 124  Error: 0.553636110337\n",
      "Epoch: 125  Error: 0.568403455001\n",
      "Epoch: 126  Error: 0.51629980496\n",
      "Epoch: 127  Error: 0.561437726386\n",
      "Epoch: 128  Error: 0.549735302313\n",
      "Epoch: 129  Error: 0.550013931457\n",
      "Epoch: 130  Error: 0.562830872109\n",
      "Epoch: 131  Error: 0.5477848983\n",
      "Epoch: 132  Error: 0.556143772639\n",
      "Epoch: 133  Error: 0.558094176651\n",
      "Epoch: 134  Error: 0.57620507105\n",
      "Epoch: 135  Error: 0.55140707718\n",
      "Epoch: 136  Error: 0.557536918362\n",
      "Epoch: 137  Error: 0.50181108944\n",
      "Epoch: 138  Error: 0.562830872109\n",
      "Epoch: 139  Error: 0.56227361382\n",
      "Epoch: 140  Error: 0.555865143494\n",
      "Epoch: 141  Error: 0.558372805795\n",
      "Epoch: 142  Error: 0.553914739482\n",
      "Epoch: 143  Error: 0.563666759543\n",
      "Epoch: 144  Error: 0.561716355531\n",
      "Epoch: 145  Error: 0.567288938423\n",
      "Epoch: 146  Error: 0.553636110337\n",
      "Epoch: 147  Error: 0.570353859014\n",
      "Epoch: 148  Error: 0.578434104207\n",
      "Epoch: 149  Error: 0.573697408749\n",
      "Epoch: 150  Error: 0.552242964614\n",
      "Epoch: 151  Error: 0.426302591251\n",
      "Epoch: 152  Error: 0.558372805795\n",
      "Epoch: 153  Error: 0.554193368626\n",
      "Epoch: 154  Error: 0.552800222903\n",
      "Epoch: 155  Error: 0.556979660072\n",
      "Epoch: 156  Error: 0.555865143494\n",
      "Epoch: 157  Error: 0.557258289217\n",
      "Epoch: 158  Error: 0.54834215659\n",
      "Epoch: 159  Error: 0.55865143494\n",
      "Epoch: 160  Error: 0.564781276121\n",
      "Epoch: 161  Error: 0.549735302313\n",
      "Epoch: 162  Error: 0.489551407077\n",
      "Epoch: 163  Error: 0.560323209808\n",
      "Epoch: 164  Error: 0.55502925606\n",
      "Epoch: 165  Error: 0.550292560602\n",
      "Epoch: 166  Error: 0.54471997771\n",
      "Epoch: 167  Error: 0.549178044023\n",
      "Epoch: 168  Error: 0.563666759543\n",
      "Epoch: 169  Error: 0.558372805795\n",
      "Epoch: 170  Error: 0.549735302313\n",
      "Epoch: 171  Error: 0.56227361382\n",
      "Epoch: 172  Error: 0.463917525773\n",
      "Epoch: 173  Error: 0.541933686264\n",
      "Epoch: 174  Error: 0.563388130398\n",
      "Epoch: 175  Error: 0.57620507105\n",
      "Epoch: 176  Error: 0.553078852048\n",
      "Epoch: 177  Error: 0.557258289217\n",
      "Epoch: 178  Error: 0.558372805795\n",
      "Epoch: 179  Error: 0.565617163555\n",
      "Epoch: 180  Error: 0.525494566732\n",
      "Epoch: 181  Error: 0.542769573697\n",
      "Epoch: 182  Error: 0.559765951519\n",
      "Epoch: 183  Error: 0.570075229869\n",
      "Epoch: 184  Error: 0.553914739482\n",
      "Epoch: 185  Error: 0.568682084146\n",
      "Epoch: 186  Error: 0.567010309278\n",
      "Epoch: 187  Error: 0.559487322374\n",
      "Epoch: 188  Error: 0.520200612984\n",
      "Epoch: 189  Error: 0.536639732516\n",
      "Epoch: 190  Error: 0.546391752577\n",
      "Epoch: 191  Error: 0.553078852048\n",
      "Epoch: 192  Error: 0.561159097242\n",
      "Epoch: 193  Error: 0.550013931457\n",
      "Epoch: 194  Error: 0.566174421845\n",
      "Epoch: 195  Error: 0.564781276121\n",
      "Epoch: 196  Error: 0.546391752577\n",
      "Epoch: 197  Error: 0.55865143494\n",
      "Epoch: 198  Error: 0.555586514349\n",
      "Epoch: 199  Error: 0.508219559766\n",
      "Epoch: 200  Error: 0.572582892171\n",
      "Epoch: 201  Error: 0.555865143494\n",
      "Epoch: 202  Error: 0.544441348565\n",
      "Epoch: 203  Error: 0.365561437726\n",
      "Epoch: 204  Error: 0.549456673168\n",
      "Epoch: 205  Error: 0.556422401783\n",
      "Epoch: 206  Error: 0.538590136528\n",
      "Epoch: 207  Error: 0.5658957927\n",
      "Epoch: 208  Error: 0.558372805795\n",
      "Epoch: 209  Error: 0.519086096406\n",
      "Epoch: 210  Error: 0.555307885205\n",
      "Epoch: 211  Error: 0.504597380886\n",
      "Epoch: 212  Error: 0.556979660072\n",
      "Epoch: 213  Error: 0.571189746447\n",
      "Epoch: 214  Error: 0.548899414879\n",
      "Epoch: 215  Error: 0.554471997771\n",
      "Epoch: 216  Error: 0.568124825857\n",
      "Epoch: 217  Error: 0.562552242965\n",
      "Epoch: 218  Error: 0.568682084146\n",
      "Epoch: 219  Error: 0.550571189746\n",
      "Epoch: 220  Error: 0.5477848983\n",
      "Epoch: 221  Error: 0.516857063249\n",
      "Epoch: 222  Error: 0.570353859014\n",
      "Epoch: 223  Error: 0.546670381722\n",
      "Epoch: 224  Error: 0.559487322374\n",
      "Epoch: 225  Error: 0.560880468097\n",
      "Epoch: 226  Error: 0.541655057119\n",
      "Epoch: 227  Error: 0.442184452494\n",
      "Epoch: 228  Error: 0.474505433268\n",
      "Epoch: 229  Error: 0.568682084146\n",
      "Epoch: 230  Error: 0.572304263026\n",
      "Epoch: 231  Error: 0.568124825857\n",
      "Epoch: 232  Error: 0.535246586793\n",
      "Epoch: 233  Error: 0.555865143494\n",
      "Epoch: 234  Error: 0.554193368626\n",
      "Epoch: 235  Error: 0.558372805795\n",
      "Epoch: 236  Error: 0.562830872109\n",
      "Epoch: 237  Error: 0.534967957648\n",
      "Epoch: 238  Error: 0.524658679298\n",
      "Epoch: 239  Error: 0.550849818891\n",
      "Epoch: 240  Error: 0.572861521315\n",
      "Epoch: 241  Error: 0.555865143494\n",
      "Epoch: 242  Error: 0.563945388688\n",
      "Epoch: 243  Error: 0.549456673168\n",
      "Epoch: 244  Error: 0.478406241293\n",
      "Epoch: 245  Error: 0.556143772639\n",
      "Epoch: 246  Error: 0.558094176651\n",
      "Epoch: 247  Error: 0.570075229869\n",
      "Epoch: 248  Error: 0.565338534411\n",
      "Epoch: 249  Error: 0.544998606854\n",
      "Epoch: 250  Error: 0.551964335469\n",
      "Epoch: 251  Error: 0.552242964614\n",
      "Epoch: 252  Error: 0.554750626916\n",
      "Epoch: 253  Error: 0.508219559766\n",
      "Epoch: 254  Error: 0.536361103371\n",
      "Epoch: 255  Error: 0.549456673168\n",
      "Epoch: 256  Error: 0.550013931457\n",
      "Epoch: 257  Error: 0.558094176651\n",
      "Epoch: 258  Error: 0.563109501254\n",
      "Epoch: 259  Error: 0.549456673168\n",
      "Epoch: 260  Error: 0.567288938423\n",
      "Epoch: 261  Error: 0.546391752577\n",
      "Epoch: 262  Error: 0.539426023962\n",
      "Epoch: 263  Error: 0.55502925606\n",
      "Epoch: 264  Error: 0.565617163555\n",
      "Epoch: 265  Error: 0.53385344107\n",
      "Epoch: 266  Error: 0.531624407913\n",
      "Epoch: 267  Error: 0.561716355531\n",
      "Epoch: 268  Error: 0.561159097242\n",
      "Epoch: 269  Error: 0.460852605183\n",
      "Epoch: 270  Error: 0.564502646977\n",
      "Epoch: 271  Error: 0.531624407913\n",
      "Epoch: 272  Error: 0.551128448036\n",
      "Epoch: 273  Error: 0.487043744776\n",
      "Epoch: 274  Error: 0.550013931457\n",
      "Epoch: 275  Error: 0.556143772639\n",
      "Epoch: 276  Error: 0.551685706325\n",
      "Epoch: 277  Error: 0.554471997771\n",
      "Epoch: 278  Error: 0.559487322374\n",
      "Epoch: 279  Error: 0.552800222903\n",
      "Epoch: 280  Error: 0.56227361382\n",
      "Epoch: 281  Error: 0.544998606854\n",
      "Epoch: 282  Error: 0.544441348565\n",
      "Epoch: 283  Error: 0.553357481193\n",
      "Epoch: 284  Error: 0.541655057119\n",
      "Epoch: 285  Error: 0.534689328504\n",
      "Epoch: 286  Error: 0.554193368626\n",
      "Epoch: 287  Error: 0.526051825021\n",
      "Epoch: 288  Error: 0.54416271942\n",
      "Epoch: 289  Error: 0.557815547506\n",
      "Epoch: 290  Error: 0.543884090276\n",
      "Epoch: 291  Error: 0.54109779883\n",
      "Epoch: 292  Error: 0.545834494288\n",
      "Epoch: 293  Error: 0.555586514349\n",
      "Epoch: 294  Error: 0.556422401783\n",
      "Epoch: 295  Error: 0.538868765673\n",
      "Epoch: 296  Error: 0.539983282251\n",
      "Epoch: 297  Error: 0.452493730844\n",
      "Epoch: 298  Error: 0.565617163555\n",
      "Epoch: 299  Error: 0.555307885205\n",
      "Epoch: 300  Error: 0.523265533575\n",
      "Epoch: 301  Error: 0.544441348565\n",
      "Epoch: 302  Error: 0.548899414879\n",
      "Epoch: 303  Error: 0.539704653107\n",
      "Epoch: 304  Error: 0.522429646141\n",
      "Epoch: 305  Error: 0.542212315408\n",
      "Epoch: 306  Error: 0.515463917526\n",
      "Epoch: 307  Error: 0.489830036222\n",
      "Epoch: 308  Error: 0.514628030092\n",
      "Epoch: 309  Error: 0.511005851212\n",
      "Epoch: 310  Error: 0.504876010031\n",
      "Epoch: 311  Error: 0.451936472555\n",
      "Epoch: 312  Error: 0.533017553636\n",
      "Epoch: 313  Error: 0.540540540541\n",
      "Epoch: 314  Error: 0.516578434104\n",
      "Epoch: 315  Error: 0.509334076344\n",
      "Epoch: 316  Error: 0.2635831708\n",
      "Epoch: 317  Error: 0.526051825021\n",
      "Epoch: 318  Error: 0.476455837281\n",
      "Epoch: 319  Error: 0.444413485651\n",
      "Epoch: 320  Error: 0.477570353859\n",
      "Epoch: 321  Error: 0.476177208136\n",
      "Epoch: 322  Error: 0.473112287545\n",
      "Epoch: 323  Error: 0.552242964614\n",
      "Epoch: 324  Error: 0.528559487322\n",
      "Epoch: 325  Error: 0.521315129563\n",
      "Epoch: 326  Error: 0.505711897464\n",
      "Epoch: 327  Error: 0.528559487322\n",
      "Epoch: 328  Error: 0.51212036779\n",
      "Epoch: 329  Error: 0.538311507384\n",
      "Epoch: 330  Error: 0.130119810532\n",
      "Epoch: 331  Error: 0.45165784341\n",
      "Epoch: 332  Error: 0.504876010031\n",
      "Epoch: 333  Error: 0.465032042352\n",
      "Epoch: 334  Error: 0.479242128727\n",
      "Epoch: 335  Error: 0.478684870437\n",
      "Epoch: 336  Error: 0.536918361661\n",
      "Epoch: 337  Error: 0.511563109501\n",
      "Epoch: 338  Error: 0.517971579827\n",
      "Epoch: 339  Error: 0.495681248259\n",
      "Epoch: 340  Error: 0.490665923656\n",
      "Epoch: 341  Error: 0.482585678462\n",
      "Epoch: 342  Error: 0.483142936751\n",
      "Epoch: 343  Error: 0.388409027584\n",
      "Epoch: 344  Error: 0.344664251881\n",
      "Epoch: 345  Error: 0.475341320702\n",
      "Epoch: 346  Error: 0.39119531903\n",
      "Epoch: 347  Error: 0.42685984954\n",
      "Epoch: 348  Error: 0.517135692393\n",
      "Epoch: 349  Error: 0.502089718585\n",
      "Epoch: 350  Error: 0.427974366119\n",
      "Epoch: 351  Error: 0.386458623572\n",
      "Epoch: 352  Error: 0.202284758986\n",
      "Epoch: 353  Error: 0.34522151017\n",
      "Epoch: 354  Error: 0.460852605183\n",
      "Epoch: 355  Error: 0.491780440234\n",
      "Epoch: 356  Error: 0.329061019783\n",
      "Epoch: 357  Error: 0.379214265812\n",
      "Epoch: 358  Error: 0.368626358317\n",
      "Epoch: 359  Error: 0.413207021454\n",
      "Epoch: 360  Error: 0.483142936751\n",
      "Epoch: 361  Error: 0.411535246587\n",
      "Epoch: 362  Error: 0.214265812204\n",
      "Epoch: 363  Error: 0.378657007523\n",
      "Epoch: 364  Error: 0.456394538869\n",
      "Epoch: 365  Error: 0.130398439677\n",
      "Epoch: 366  Error: 0.130119810532\n",
      "Epoch: 367  Error: 0.130119810532\n",
      "Epoch: 368  Error: 0.130119810532\n",
      "Epoch: 369  Error: 0.130119810532\n",
      "Epoch: 370  Error: 0.130119810532\n",
      "Epoch: 371  Error: 0.130119810532\n",
      "Epoch: 372  Error: 0.130119810532\n",
      "Epoch: 373  Error: 0.130119810532\n",
      "Epoch: 374  Error: 0.130677068821\n",
      "Epoch: 375  Error: 0.130398439677\n",
      "Epoch: 376  Error: 0.130955697966\n",
      "Epoch: 377  Error: 0.130119810532\n",
      "Epoch: 378  Error: 0.130119810532\n",
      "Epoch: 379  Error: 0.130119810532\n",
      "Epoch: 380  Error: 0.131512956255\n",
      "Epoch: 381  Error: 0.130119810532\n",
      "Epoch: 382  Error: 0.130119810532\n",
      "Epoch: 383  Error: 0.130119810532\n",
      "Epoch: 384  Error: 0.130119810532\n",
      "Epoch: 385  Error: 0.130119810532\n",
      "Epoch: 386  Error: 0.130119810532\n",
      "Epoch: 387  Error: 0.130119810532\n",
      "Epoch: 388  Error: 0.130119810532\n",
      "Epoch: 389  Error: 0.129841181388\n",
      "Epoch: 390  Error: 0.130119810532\n",
      "Epoch: 391  Error: 0.130119810532\n",
      "Epoch: 392  Error: 0.130119810532\n",
      "Epoch: 393  Error: 0.130119810532\n",
      "Epoch: 394  Error: 0.130119810532\n",
      "Epoch: 395  Error: 0.130119810532\n",
      "Epoch: 396  Error: 0.130119810532\n",
      "Epoch: 397  Error: 0.130119810532\n",
      "Epoch: 398  Error: 0.130119810532\n",
      "Epoch: 399  Error: 0.130119810532\n",
      "Epoch: 400  Error: 0.130119810532\n",
      "Epoch: 401  Error: 0.130119810532\n",
      "Epoch: 402  Error: 0.130119810532\n",
      "Epoch: 403  Error: 0.130119810532\n",
      "Epoch: 404  Error: 0.130119810532\n",
      "Epoch: 405  Error: 0.130119810532\n",
      "Epoch: 406  Error: 0.130119810532\n",
      "Epoch: 407  Error: 0.130119810532\n",
      "Epoch: 408  Error: 0.130119810532\n",
      "Epoch: 409  Error: 0.130119810532\n",
      "Epoch: 410  Error: 0.130119810532\n",
      "Epoch: 411  Error: 0.130398439677\n",
      "Epoch: 412  Error: 0.130119810532\n",
      "Epoch: 413  Error: 0.130119810532\n",
      "Epoch: 414  Error: 0.130119810532\n",
      "Epoch: 415  Error: 0.130119810532\n",
      "Epoch: 416  Error: 0.130119810532\n",
      "Epoch: 417  Error: 0.130119810532\n",
      "Epoch: 418  Error: 0.130119810532\n",
      "Epoch: 419  Error: 0.130119810532\n",
      "Epoch: 420  Error: 0.130119810532\n",
      "Epoch: 421  Error: 0.130119810532\n",
      "Epoch: 422  Error: 0.130119810532\n",
      "Epoch: 423  Error: 0.130119810532\n",
      "Epoch: 424  Error: 0.130119810532\n",
      "Epoch: 425  Error: 0.130119810532\n",
      "Epoch: 426  Error: 0.130119810532\n",
      "Epoch: 427  Error: 0.130119810532\n",
      "Epoch: 428  Error: 0.130119810532\n",
      "Epoch: 429  Error: 0.130119810532\n",
      "Epoch: 430  Error: 0.134856505991\n",
      "Epoch: 431  Error: 0.130119810532\n",
      "Epoch: 432  Error: 0.130119810532\n",
      "Epoch: 433  Error: 0.130119810532\n",
      "Epoch: 434  Error: 0.130119810532\n",
      "Epoch: 435  Error: 0.130119810532\n",
      "Epoch: 436  Error: 0.130119810532\n",
      "Epoch: 437  Error: 0.130119810532\n",
      "Epoch: 438  Error: 0.130119810532\n",
      "Epoch: 439  Error: 0.130119810532\n",
      "Epoch: 440  Error: 0.130119810532\n",
      "Epoch: 441  Error: 0.130119810532\n",
      "Epoch: 442  Error: 0.130119810532\n",
      "Epoch: 443  Error: 0.130119810532\n",
      "Epoch: 444  Error: 0.130119810532\n",
      "Epoch: 445  Error: 0.130119810532\n",
      "Epoch: 446  Error: 0.130119810532\n",
      "Epoch: 447  Error: 0.130119810532\n",
      "Epoch: 448  Error: 0.130398439677\n",
      "Epoch: 449  Error: 0.130398439677\n",
      "Epoch: 450  Error: 0.130677068821\n",
      "Epoch: 451  Error: 0.130119810532\n",
      "Epoch: 452  Error: 0.130119810532\n",
      "Epoch: 453  Error: 0.130119810532\n",
      "Epoch: 454  Error: 0.130119810532\n",
      "Epoch: 455  Error: 0.130677068821\n",
      "Epoch: 456  Error: 0.129841181388\n",
      "Epoch: 457  Error: 0.130119810532\n",
      "Epoch: 458  Error: 0.130119810532\n",
      "Epoch: 459  Error: 0.130119810532\n",
      "Epoch: 460  Error: 0.130119810532\n",
      "Epoch: 461  Error: 0.130119810532\n",
      "Epoch: 462  Error: 0.130119810532\n",
      "Epoch: 463  Error: 0.130119810532\n",
      "Epoch: 464  Error: 0.130119810532\n",
      "Epoch: 465  Error: 0.130119810532\n",
      "Epoch: 466  Error: 0.130119810532\n",
      "Epoch: 467  Error: 0.130119810532\n",
      "Epoch: 468  Error: 0.130119810532\n",
      "Epoch: 469  Error: 0.130119810532\n",
      "Epoch: 470  Error: 0.130119810532\n",
      "Epoch: 471  Error: 0.130119810532\n",
      "Epoch: 472  Error: 0.130119810532\n",
      "Epoch: 473  Error: 0.130398439677\n",
      "Epoch: 474  Error: 0.151016996378\n",
      "Epoch: 475  Error: 0.130119810532\n",
      "Epoch: 476  Error: 0.130119810532\n",
      "Epoch: 477  Error: 0.130119810532\n",
      "Epoch: 478  Error: 0.130119810532\n",
      "Epoch: 479  Error: 0.130119810532\n",
      "Epoch: 480  Error: 0.130119810532\n",
      "Epoch: 481  Error: 0.130119810532\n",
      "Epoch: 482  Error: 0.130119810532\n",
      "Epoch: 483  Error: 0.130119810532\n",
      "Epoch: 484  Error: 0.130119810532\n",
      "Epoch: 485  Error: 0.130119810532\n",
      "Epoch: 486  Error: 0.130119810532\n",
      "Epoch: 487  Error: 0.130119810532\n",
      "Epoch: 488  Error: 0.130119810532\n",
      "Epoch: 489  Error: 0.130119810532\n",
      "Epoch: 490  Error: 0.130119810532\n",
      "Epoch: 491  Error: 0.130119810532\n",
      "Epoch: 492  Error: 0.130119810532\n",
      "Epoch: 493  Error: 0.130119810532\n",
      "Epoch: 494  Error: 0.130119810532\n",
      "Epoch: 495  Error: 0.130119810532\n",
      "Epoch: 496  Error: 0.130119810532\n",
      "Epoch: 497  Error: 0.130119810532\n",
      "Epoch: 498  Error: 0.13847868487\n",
      "Epoch: 499  Error: 0.13847868487\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    error = np.mean(np.argmax(teY, axis=1) == predict(teX))\n",
    "    logline = \"Epoch: \" + str(i) + \"  Error: \" + str(error)\n",
    "    print logline\n",
    "    f = open(logPickle, 'a+')\n",
    "    pickle.dump(logline , f);\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion = (np.argmax(teY, axis=1) == predict(teX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False ...,  True False False]\n"
     ]
    }
   ],
   "source": [
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589,)\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(teX)\n",
    "print predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real = np.argmax(teY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion = np.zeros((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0 , len(real)):\n",
    "    j = real[i]\n",
    "    k = predicted[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 210.    4.   51.   47.   92.   11.   52.]\n",
      " [   9.   24.    5.    4.    9.    1.    4.]\n",
      " [  45.    2.  153.   47.  139.   48.   62.]\n",
      " [  39.    0.   22.  716.   44.   19.   55.]\n",
      " [ 105.    6.   41.   79.  313.   15.   94.]\n",
      " [  28.    0.   27.   25.   21.  295.   19.]\n",
      " [  72.    0.   28.   85.  123.   12.  287.]]\n"
     ]
    }
   ],
   "source": [
    "print confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550321199143\n",
      "0.571428571429\n",
      "0.691532258065\n",
      "0.2\n",
      "0.52067381317\n",
      "0.289156626506\n",
      "0.527182866557\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,7):\n",
    "    #print (confusion[j][j]/sum(confusion[j][:]))\n",
    "    print (sum(confusion[j][:]) - confusion[j][j])/sum(confusion[j][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([467,  56, 496, 895, 653, 415, 607]), array([0, 1, 2, 3, 4, 5, 6, 7]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(real , bins=[0,1, 2, 3 , 4 , 5 , 6 , 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =======Saving Network params==== \n"
     ]
    }
   ],
   "source": [
    "logline = \" =======Saving Network params==== \"\n",
    "print logline\n",
    "f = open(logPickle, 'a+')\n",
    "f2 = open(parampickle , 'a+')\n",
    "pickle.dump(logline , f);\n",
    "pickle.dump(params , f2)\n",
    "f2.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = open(parampickle , 'a+')\n",
    "for p in params:\n",
    "    pickle.dump(p.get_value(),f2)\n",
    "    \n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
