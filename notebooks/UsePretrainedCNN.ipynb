{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../lib\")\n",
    "from load import getValData\n",
    "from load import faces\n",
    "import pickle\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "from six.moves import cPickle\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "# trX = trX.reshape(-1, 1, 28, 28)\n",
    "# teX = teX.reshape(-1, 1, 28, 28)\n",
    "\n",
    "trX, teX, trY, teY = faces(onehot=True)\n",
    "\n",
    "#ValX , ValY = getValData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX = trX.reshape(-1, 1, 48, 48)\n",
    "teX = teX.reshape(-1, 1, 48, 48)\n",
    "#ValX = ValX.reshape(-1, 1, 48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ValX = genfromtxt('../CKPlus/CKfaces.csv', delimiter=',')\n",
    "ValX = ValX.reshape(-1, 1, 48, 48)\n",
    "ValY = genfromtxt('../CKPlus/labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('../Logs/MsftTestScores.pkl', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSFTPredict = np.zeros((len(lists),7))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(',')\n",
    "    for j in range(0,7):\n",
    "        MSFTPredict[i][j]=float(log[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('../Logs/MsftTestScoresCKplus.pkl', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()\n",
    "\n",
    "MSFTPredictCK = np.zeros((len(lists),7))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(',')\n",
    "    for j in range(0,7):\n",
    "        MSFTPredictCK[i][j]=float(log[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n",
      "0.558372805795\n"
     ]
    }
   ],
   "source": [
    "print MSFTPredict.shape\n",
    "\n",
    "A = np.argmax(teY, axis=1)\n",
    "B = np.argmax(MSFTPredict, axis=1)\n",
    "print np.mean(A == B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.   0.   0.   0.   0.   0.  36.]\n",
      " [  6.  46.   0.   9.   0.   0.  16.]\n",
      " [  0.   3.   9.   5.   6.   2.   0.]\n",
      " [  1.   0.   0.  68.   0.   0.   0.]\n",
      " [  1.   0.   0.   0.  16.   0.  11.]\n",
      " [  1.   0.   0.   1.   0.  78.   3.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "confusion = np.zeros((7,7))\n",
    "for i in range(0 , len(A)):\n",
    "    j = A[i]\n",
    "    k = B[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: \n",
      "0.2\n",
      "0.597402597403\n",
      "0.36\n",
      "0.985507246377\n",
      "0.571428571429\n",
      "0.939759036145\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print \"Precision: \"\n",
    "for j in range(0,7):\n",
    "    print (confusion[j][j]/sum(confusion[j][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testCount = np.sum(teY , axis = 0)\n",
    "# trainCount = np.sum(ValY , axis = 0)\n",
    "# print testCount , trainCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r = len(ValY)\n",
    "# i = 0\n",
    "# while i < r:\n",
    "#     if(ValY[i][6] == 1):\n",
    "#         ValX = np.delete(ValX , i , 0)\n",
    "#         ValY = np.delete(ValY , i , 0)\n",
    "#         i = i-1\n",
    "#         r = len(ValY)\n",
    "#     else:\n",
    "#         i = i+1\n",
    "\n",
    "# r = len(teY) \n",
    "# i = 0\n",
    "# while i < r:\n",
    "#     if(teY[i][6] == 1):\n",
    "#         teX = np.delete(teX , i , 0)\n",
    "#         teY = np.delete(teY , i , 0)\n",
    "#         i = i-1\n",
    "#         r = len(teY)\n",
    "#     else:\n",
    "#         i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testCount = np.sum(teY , axis = 0)\n",
    "# trainCount = np.sum(ValY , axis = 0)\n",
    "# print testCount , trainCount\n",
    "# teY = np.delete(teY , 6 , 1)\n",
    "# trY = np.delete(trY , 6 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n",
      "[0 1 4 ..., 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "#print trY.shape\n",
    "print teY.shape\n",
    "print np.argmax(teY , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    W = theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "    return W\n",
    "\n",
    "def init_bias(shape):\n",
    "    b_values = np.zeros((shape[0],), dtype=theano.config.floatX)\n",
    "    b = theano.shared(value=b_values, borrow=True )\n",
    "    return b\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X *  srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X = (X/retain_prob)\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def negative_log_likelihood(p_y_given_x,y):\n",
    "        \"\"\"Return the mean of the negative log-likelihood of the prediction\n",
    "        of this model under a given target distribution.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n",
    "            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n",
    "                \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) \\\\\n",
    "            \\ell (\\theta=\\{W,b\\}, \\mathcal{D})\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "\n",
    "        Note: we use the mean instead of the sum so that\n",
    "              the learning rate is less dependent on the batch size\n",
    "        \"\"\"\n",
    "        # start-snippet-2\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of examples (call it n) in the minibatch\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w, b , w2, b2 ,  w3, b3, w4, b4, w5 , b5, w6 , b6 , w_o, b_o, p_drop_conv, p_drop_hidden):\n",
    "    l1a = conv2d(X, w)\n",
    "    l1a = rectify(l1a + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = conv2d(l1, w2)\n",
    "    l2a = rectify(l2a + b2.dimshuffle('x', 0, 'x', 'x'))\n",
    "    #l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2a, p_drop_conv)\n",
    "    \n",
    "    l3a = conv2d(l2, w3)\n",
    "    l3a = rectify(l3a + b3.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l3 = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4a = conv2d(l3, w4)\n",
    "    l4b = rectify(l4a + b4.dimshuffle('x', 0, 'x', 'x'))\n",
    "    l4 = T.flatten(l4b, outdim=2)\n",
    "    l4 = dropout(l4, p_drop_conv)\n",
    "\n",
    "    l5 = rectify(T.dot(l4, w5) + b5.dimshuffle('x', 0 ))\n",
    "    l5 = dropout(l5, p_drop_hidden)\n",
    "    \n",
    "    l6 = rectify(T.dot(l5, w6) + b6.dimshuffle('x', 0))\n",
    "    l6 = dropout(l6, p_drop_hidden)\n",
    "\n",
    "    # Add numerically stable softmax\n",
    "    #pyx = T.nnet.softmax(T.dot(l6, w_o) + b_o.dimshuffle('x', 0))\n",
    "    opVec = T.dot(l6, w_o) + b_o.dimshuffle('x', 0)\n",
    "    xdev = opVec-opVec.max(1,keepdims=True)\n",
    "    pyx = xdev - T.log(T.sum(T.exp(xdev),axis=1,keepdims=True))\n",
    "    return l1, l2, l3, l4, l5, l6, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict Loop\n",
    "modelParams = open(\"ModelsV1/ModelSnapshot1000.pkl\")\n",
    "Params = cPickle.load(modelParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "l1, l2, l3, l4, l5,l6, py_x = model(X, Params[0], Params[1], Params[2], Params[3], Params[4], Params[5], Params[6], Params[7], Params[8], Params[9], Params[10], Params[11], Params[12], Params[13], 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probpredict = theano.function(inputs=[X], outputs=py_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638060741154\n",
      "0.559633027523\n"
     ]
    }
   ],
   "source": [
    "errorVal = np.mean(np.argmax(ValY, axis=1) == predict(ValX))\n",
    "error = np.mean(np.argmax(teY, axis=1) == predict(teX))\n",
    "print error\n",
    "print errorVal\n",
    "\n",
    "# prediction = predict(teX)\n",
    "# print prediction.shape\n",
    "# print np.argmax(teY , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.   0.   2.   0.  14.   0.  15.]\n",
      " [ 38.   6.   1.   5.  11.   0.  16.]\n",
      " [  0.   3.   3.   6.   5.   2.   6.]\n",
      " [  1.   0.   0.  68.   0.   0.   0.]\n",
      " [  4.   1.   3.   0.  15.   1.   4.]\n",
      " [  1.   0.   0.   1.   3.  77.   1.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(ValX)\n",
    "real = np.argmax(ValY, axis=1)\n",
    "confusion = np.zeros((7,7))\n",
    "for i in range(0 , len(real)):\n",
    "    j = real[i]\n",
    "    k = predicted[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print MSFTPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_val = probpredict(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_test = probpredict(ValX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print py_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Bayesian classifier here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589, 14)\n",
      "0.558372805795\n"
     ]
    }
   ],
   "source": [
    "compound_result = np.concatenate((py_val,MSFTPredict ), axis=1)\n",
    "print compound_result.shape\n",
    "error_compound = np.mean(np.argmax(teY, axis=1) == (np.argmax(compound_result, axis=1)%7) )\n",
    "print error_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 14)\n",
      "0.691131498471\n"
     ]
    }
   ],
   "source": [
    "compound_test = np.concatenate((py_test,MSFTPredictCK ), axis=1)\n",
    "print compound_test.shape\n",
    "error_test = np.mean(np.argmax(ValY, axis=1) == (np.argmax(compound_test, axis=1)%7) )\n",
    "print error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "labels = np.argmax(teY, axis=1)\n",
    "compound_result[compound_result < 0] = 0\n",
    "clf.fit(compound_result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327,)\n"
     ]
    }
   ],
   "source": [
    "bayesian_predict = clf.predict(compound_test)\n",
    "print bayesian_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74006116208\n"
     ]
    }
   ],
   "source": [
    "error_bayesian = np.mean(np.argmax(ValY, axis=1) == bayesian_predict )\n",
    "print error_bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.   3.   3.   1.   1.   1.   0.]\n",
      " [  0.  53.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.  10.   0.   0.   0.   0.]\n",
      " [  0.   9.   2.  68.   0.   2.   0.]\n",
      " [  4.   0.   5.   0.  19.   0.   0.]\n",
      " [  0.   0.   2.   0.   0.  80.   0.]\n",
      " [ 29.  12.   2.   0.   8.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "ans = np.argmax(ValY, axis=1)\n",
    "confusion = np.zeros((7,7))\n",
    "for i in range(0 , len(bayesian_predict)):\n",
    "    j = bayesian_predict[i]\n",
    "    k = ans[i]\n",
    "    #print \"Real:  %d , predicted %d\"%(j,k)\n",
    "    confusion[j][k] = confusion[j][k] + 1\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: \n",
      "0.571428571429\n",
      "0.981481481481\n",
      "1.0\n",
      "0.83950617284\n",
      "0.678571428571\n",
      "0.975609756098\n",
      "0.0\n",
      "true negatives : \n",
      "0.428571428571\n",
      "0.0185185185185\n",
      "0.0\n",
      "0.16049382716\n",
      "0.321428571429\n",
      "0.0243902439024\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print \"Precision: \"\n",
    "for j in range(0,7):\n",
    "    print (confusion[j][j]/sum(confusion[:][j]))\n",
    "\n",
    "print \"true negatives : \"\n",
    "for j in range(0,7):\n",
    "    print (sum(confusion[j][:]) - confusion[j][j])/sum(confusion[j][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lists = []\n",
    "infile = open('ErrosCNN7LayersV2.pickle', 'r')\n",
    "while 1:\n",
    "    try:\n",
    "        lists.append(pickle.load(infile))\n",
    "    except (EOFError):\n",
    "        break\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = np.zeros((len(lists),))\n",
    "cost = np.zeros((len(lists),))\n",
    "for i in range(len(lists)):\n",
    "    log = lists[i].split(' ')\n",
    "    errors[i] = float(log[4])\n",
    "    cost[i] = float(log[6])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cost)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Train time Cost Transition')\n",
    "plt.show()\n",
    "plt.savefig('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(errors)\n",
    "plt.ylabel('Prediction Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Train time Prediction Accuracy Transition')\n",
    "plt.show()\n",
    "plt.savefig('prediction_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = Params[0].get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = A.reshape(64,1*7*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = T.flatten(Params[0], outdim=2)\n",
    "print image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = tile_raster_images(A ,(7,7) , (7,7) ,(3,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(filters,cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
