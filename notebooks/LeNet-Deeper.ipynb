{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano.tensor.nnet import conv\n",
    "import sys\n",
    "sys.path.append(\"../lib\")\n",
    "from logistic_sgd import LogisticRegression, load_data\n",
    "from mlp import HiddenLayer\n",
    "from mlp import MLP\n",
    "from load import mnist\n",
    "from load import faces\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY  = faces(onehot = False)\n",
    "#trX, teX, trY, teY  = mnist(onehot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 2304)\n"
     ]
    }
   ],
   "source": [
    "print trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainX = trX[:25000]\n",
    "ValX = trX[25000:]\n",
    "TrainY = trY[:25000]\n",
    "ValY = trY[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3709, 2304)\n",
      "(25000, 2304)\n",
      "(3589, 2304)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD+CAYAAADxoQNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4457fef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanValidate = numpy.mean(TrainX , axis = 0);\n",
    "meanValidate = meanValidate.reshape(48, 48)\n",
    "#imshow(meanValidate,cmap = cm.Greys_r)\n",
    "imshow(ValX[100].reshape(48,48),cmap = cm.Greys_r)\n",
    "\n",
    "print ValX.shape\n",
    "print TrainX.shape\n",
    "print teX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x = theano.shared(numpy.asarray(TrainX, dtype=theano.config.floatX),borrow=True)\n",
    "test_set_x = theano.shared(numpy.asarray(teX, dtype=theano.config.floatX),borrow=True)\n",
    "train_set_y = theano.shared(numpy.asarray(TrainY, dtype=\"int32\"),borrow=True)\n",
    "test_set_y = theano.shared(numpy.asarray(teY, dtype=\"int32\"),borrow=True)\n",
    "\n",
    "val_set_x = theano.shared(numpy.asarray(ValX, dtype=theano.config.floatX),borrow=True)\n",
    "val_set_y = theano.shared(numpy.asarray(ValY, dtype=\"int32\"),borrow=True)\n",
    "\n",
    "datasets = [(train_set_x, train_set_y), (val_set_x, val_set_y),(test_set_x, test_set_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X *  srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X = (X/retain_prob)\n",
    "    return X\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LeNetConvPoolLayer(object):\n",
    "    \"\"\"Pool Layer of a convolutional network \"\"\"\n",
    "    def __init__(self, rng, input, filter_shape, image_shape, poolsize=(2, 2)):\n",
    "    \n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "        self.input = input\n",
    "\n",
    "        print \"image Shape: \" + str(image_shape)\n",
    "        print \"filter Shape\" + str(filter_shape)\n",
    "\n",
    "        # there are \"num input feature maps * filter height * filter width\"\n",
    "        # inputs to each hidden unit\n",
    "        fan_in = numpy.prod(filter_shape[1:])\n",
    "        # each unit in the lower layer receives a gradient from:\n",
    "        # \"num output feature maps * filter height * filter width\" /\n",
    "        #   pooling size\n",
    "        fan_out = (filter_shape[0] * numpy.prod(filter_shape[2:]) /\n",
    "                   numpy.prod(poolsize))\n",
    "        # initialize weights with random weights\n",
    "        W_bound = numpy.sqrt(6. / (fan_in + fan_out))\n",
    "        self.W = theano.shared(\n",
    "            numpy.asarray(\n",
    "                rng.uniform(low=-W_bound, high=W_bound, size=filter_shape),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "        # the bias is a 1D tensor -- one bias per output feature map\n",
    "        b_values = numpy.zeros((filter_shape[0],), dtype=theano.config.floatX)\n",
    "        self.b = theano.shared(value=b_values, borrow=True)\n",
    "\n",
    "        # convolve input feature maps with filters\n",
    "        conv_out = conv.conv2d(\n",
    "            input=input,\n",
    "            filters=self.W,\n",
    "            filter_shape=filter_shape,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "        # downsample each feature map individually, using maxpooling\n",
    "        pooled_out = downsample.max_pool_2d(\n",
    "            input=conv_out,\n",
    "            ds=poolsize,\n",
    "            ignore_border=False\n",
    "        )\n",
    "\n",
    "        # add the bias term. Since the bias is a vector (1D array), we first\n",
    "        # reshape it to a tensor of shape (1, n_filters, 1, 1). Each bias will\n",
    "        # thus be broadcasted across mini-batches and feature map\n",
    "        # width & height\n",
    "        \n",
    "        #self.output = T.tanh(pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "        self.output = rectify(pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "\n",
    "        # store parameters of this layer\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "        # keep track of model input\n",
    "        self.input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_lenet5(learning_rate=0.1, n_epochs=200,\n",
    "                    dataset='mnist.pkl.gz',\n",
    "                    nkerns=[64, 128 , 256 , 512], batch_size=128):\n",
    "    \"\"\" Demonstrates lenet on MNIST dataset\n",
    "\n",
    "    :type learning_rate: float\n",
    "    :param learning_rate: learning rate used (factor for the stochastic\n",
    "                          gradient)\n",
    "\n",
    "    :type n_epochs: int\n",
    "    :param n_epochs: maximal number of epochs to run the optimizer\n",
    "\n",
    "    :type dataset: string\n",
    "    :param dataset: path to the dataset used for training /testing (MNIST here)\n",
    "\n",
    "    :type nkerns: list of ints\n",
    "    :param nkerns: number of kernels on each layer\n",
    "    \"\"\"\n",
    "\n",
    "    rng = numpy.random.RandomState(23455)\n",
    "\n",
    "    datasets = dataset\n",
    "\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "    valid_set_x, valid_set_y = datasets[1]\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "    \n",
    "    print train_set_x.get_value().shape\n",
    "    print train_set_y.get_value().shape\n",
    "    print valid_set_x.get_value().shape\n",
    "    print valid_set_y.get_value().shape\n",
    "    print test_set_x.get_value().shape\n",
    "    print test_set_y.get_value().shape\n",
    "    \n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0]\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\n",
    "    n_test_batches = test_set_x.get_value(borrow=True).shape[0]\n",
    "    n_train_batches /= batch_size\n",
    "    n_valid_batches /= batch_size\n",
    "    n_test_batches /= batch_size\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "\n",
    "    # start-snippet-1\n",
    "    x = T.matrix('x')   # the data is presented as rasterized images\n",
    "    y = T.ivector('y')  # the labels are presented as 1D vector of\n",
    "                        # [int] labels\n",
    "\n",
    "    ######################\n",
    "    # BUILD ACTUAL MODEL #\n",
    "    ######################\n",
    "    print '... building the model'\n",
    "\n",
    "    # Reshape matrix of rasterized images of shape (batch_size, 28 * 28)\n",
    "    # to a 4D tensor, compatible with our LeNetConvPoolLayer\n",
    "    # (28, 28) is the size of MNIST images.\n",
    "    layer0_input = x.reshape((batch_size, 1, 48, 48))\n",
    "\n",
    "    # Construct the first convolutional pooling layer:\n",
    "    # filtering reduces the image size to (28-5+1 , 28-5+1) = (24, 24)\n",
    "    # maxpooling reduces this further to (24/2, 24/2) = (12, 12)\n",
    "    # 4D output tensor is thus of shape (batch_size, nkerns[0], 12, 12)\n",
    "    layer0 = LeNetConvPoolLayer(\n",
    "        rng,\n",
    "        input=layer0_input,\n",
    "        image_shape=(batch_size, 1, 48, 48),\n",
    "        filter_shape=(nkerns[0], 1, 7, 7),\n",
    "        poolsize=(2, 2)\n",
    "    )\n",
    "\n",
    "    layer1_input = dropout(layer0.output, 0.5)\n",
    "    # Construct the second convolutional pooling layer\n",
    "    # filtering reduces the image size to (12-5+1, 12-5+1) = (8, 8)\n",
    "    # maxpooling reduces this further to (8/2, 8/2) = (4, 4)\n",
    "    # 4D output tensor is thus of shape (batch_size, nkerns[1], 4, 4)\n",
    "    layer1 = LeNetConvPoolLayer(\n",
    "        rng,\n",
    "        input=layer1_input,\n",
    "        image_shape=(batch_size, nkerns[0], 21, 21),\n",
    "        filter_shape=(nkerns[1], nkerns[0], 5, 5),\n",
    "        poolsize=(2, 2)\n",
    "    )\n",
    "    \n",
    "    layer2_input = dropout(layer1.output, 0.4)\n",
    "    layer2 = LeNetConvPoolLayer(\n",
    "        rng,\n",
    "        input=layer2_input,\n",
    "        image_shape=(batch_size, nkerns[1], 9 , 9),\n",
    "        filter_shape=(nkerns[2], nkerns[1], 3, 3),\n",
    "        poolsize=(1, 1)\n",
    "    )\n",
    "    \n",
    "    layer3_input = dropout(layer2.output, 0.5)\n",
    "    layer3 = LeNetConvPoolLayer(\n",
    "        rng,\n",
    "        input=layer3_input,\n",
    "        image_shape=(batch_size, nkerns[2], 7, 7),\n",
    "        filter_shape=(nkerns[3], nkerns[2], 3, 3),\n",
    "        poolsize=(2, 2)\n",
    "    )\n",
    "\n",
    "\n",
    "    # the HiddenLayer being fully-connected, it operates on 2D matrices of\n",
    "    # shape (batch_size, num_pixels) (i.e matrix of rasterized images).\n",
    "    # This will generate a matrix of shape (batch_size, nkerns[1] * 4 * 4),\n",
    "    # or (500, 50 * 4 * 4) = (500, 800) with the default values.\n",
    "    layer4_input = layer3.output.flatten(2)\n",
    "    layer4_input = dropout(layer4_input, 0.5)\n",
    "\n",
    "    # construct a fully-connected sigmoidal layer\n",
    "    layer4 = HiddenLayer(\n",
    "        rng,\n",
    "        input=layer4_input,\n",
    "        n_in=nkerns[3] * 3 * 3,\n",
    "        n_out=1000,\n",
    "        activation=T.tanh\n",
    "    )\n",
    "    \n",
    "    layer5 = MLP(\n",
    "        rng,\n",
    "        input = layer4.output,\n",
    "        n_in = 1000,\n",
    "        n_hidden=1000,\n",
    "        n_out=7\n",
    "    )\n",
    "    \n",
    "\n",
    "    # classify the values of the fully-connected sigmoidal layer\n",
    "    #layer4 = LogisticRegression(input=layer3.output, n_in=1000, n_out=10)\n",
    "\n",
    "    # the cost we minimize during training is the NLL of the model\n",
    "    cost = layer5.negative_log_likelihood(y)\n",
    "\n",
    "    # create a function to compute the mistakes that are made by the model\n",
    "    test_model = theano.function(\n",
    "        [index],\n",
    "        layer5.errors(y),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    validate_model = theano.function(\n",
    "        [index],\n",
    "        layer5.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create a list of all model parameters to be fit by gradient descent\n",
    "    params = layer5.params + layer4.params + layer3.params + layer2.params + layer1.params + layer0.params\n",
    "\n",
    "    # create a list of gradients for all model parameters\n",
    "    # grads = T.grad(cost, params)\n",
    "\n",
    "    # train_model is a function that updates the model parameters by\n",
    "    # SGD Since this model has many parameters, it would be tedious to\n",
    "    # manually create an update rule for each model parameter. We thus\n",
    "    # create the updates list by automatically looping over all\n",
    "    # (params[i], grads[i]) pairs.\n",
    "#     updates = [\n",
    "#         (param_i, param_i - learning_rate * grad_i)\n",
    "#         for param_i, grad_i in zip(params, grads)\n",
    "#     ]\n",
    "    \n",
    "    updates = RMSprop(cost , params, lr=0.0009)\n",
    "    \n",
    "    train_model = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "    # end-snippet-1\n",
    "\n",
    "    ###############\n",
    "    # TRAIN MODEL #\n",
    "    ###############\n",
    "    print '... training'\n",
    "    # early-stopping parameters\n",
    "    patience = 10000  # look as this many examples regardless\n",
    "    patience_increase = 2  # wait this much longer when a new best is\n",
    "                           # found\n",
    "    improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                   # considered significant\n",
    "    validation_frequency = min(n_train_batches, patience / 2)\n",
    "                                  # go through this many\n",
    "                                  # minibatche before checking the network\n",
    "                                  # on the validation set; in this case we\n",
    "                                  # check every epoch\n",
    "\n",
    "    best_validation_loss = numpy.inf\n",
    "    best_iter = 0\n",
    "    test_score = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    epoch = 0\n",
    "    done_looping = False\n",
    "\n",
    "    while (epoch < n_epochs) and (not done_looping):\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in xrange(n_train_batches):\n",
    "\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "\n",
    "            if iter % 100 == 0:\n",
    "                print 'training @ iter = ', iter\n",
    "            cost_ij = train_model(minibatch_index)\n",
    "\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "\n",
    "                # compute zero-one loss on validation set\n",
    "                validation_losses = [validate_model(i) for i\n",
    "                                     in xrange(n_valid_batches)]\n",
    "                this_validation_loss = numpy.mean(validation_losses)\n",
    "                print('epoch %i, minibatch %i/%i, validation error %f %%' %\n",
    "                      (epoch, minibatch_index + 1, n_train_batches,\n",
    "                       this_validation_loss * 100.))\n",
    "\n",
    "                # if we got the best validation score until now\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "\n",
    "                    #improve patience if loss improvement is good enough\n",
    "                    if this_validation_loss < best_validation_loss *  \\\n",
    "                       improvement_threshold:\n",
    "                        patience = max(patience, iter * patience_increase)\n",
    "\n",
    "                    # save best validation score and iteration number\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    best_iter = iter\n",
    "\n",
    "                    # test it on the test set\n",
    "                    test_losses = [\n",
    "                        test_model(i)\n",
    "                        for i in xrange(n_test_batches)\n",
    "                    ]\n",
    "                    test_score = numpy.mean(test_losses)\n",
    "                    print(('     epoch %i, minibatch %i/%i, test error of '\n",
    "                           'best model %f %%') %\n",
    "                          (epoch, minibatch_index + 1, n_train_batches,\n",
    "                           test_score * 100.))\n",
    "\n",
    "            if patience <= iter:\n",
    "                done_looping = True\n",
    "                break\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    print('Optimization complete.')\n",
    "    print('Best validation score of %f %% obtained at iteration %i, '\n",
    "          'with test performance %f %%' %\n",
    "          (best_validation_loss * 100., best_iter + 1, test_score * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2304)\n",
      "(25000,)\n",
      "(3709, 2304)\n",
      "(3709,)\n",
      "(3589, 2304)\n",
      "(3589,)\n",
      "... building the model\n",
      "image Shape: (128, 1, 48, 48)\n",
      "filter Shape(64, 1, 7, 7)\n",
      "image Shape: (128, 64, 21, 21)\n",
      "filter Shape(128, 64, 5, 5)\n",
      "image Shape: (128, 128, 9, 9)\n",
      "filter Shape(256, 128, 3, 3)\n",
      "image Shape: (128, 256, 7, 7)\n",
      "filter Shape(512, 256, 3, 3)\n",
      "FC layer W matrix size : 4608 X 1000\n",
      "FC layer Bias size : 1000 X 1\n",
      "FC layer W matrix size : 1000 X 1000\n",
      "FC layer Bias size : 1000 X 1\n",
      "... training\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "epoch 1, minibatch 195/195, validation error 75.223214 %\n",
      "     epoch 1, minibatch 195/195, test error of best model 75.055804 %\n",
      "training @ iter =  200\n",
      "training @ iter =  300\n",
      "epoch 2, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "epoch 3, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "epoch 4, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  800\n",
      "training @ iter =  900\n",
      "epoch 5, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "epoch 6, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "epoch 7, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  1400\n",
      "training @ iter =  1500\n",
      "epoch 8, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  1600\n",
      "training @ iter =  1700\n",
      "epoch 9, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  1800\n",
      "training @ iter =  1900\n",
      "epoch 10, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  2000\n",
      "training @ iter =  2100\n",
      "epoch 11, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  2200\n",
      "training @ iter =  2300\n",
      "epoch 12, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  2400\n",
      "training @ iter =  2500\n",
      "epoch 13, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  2600\n",
      "training @ iter =  2700\n",
      "epoch 14, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  2800\n",
      "training @ iter =  2900\n",
      "epoch 15, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3000\n",
      "training @ iter =  3100\n",
      "epoch 16, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3200\n",
      "training @ iter =  3300\n",
      "epoch 17, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3400\n",
      "training @ iter =  3500\n",
      "epoch 18, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3600\n",
      "training @ iter =  3700\n",
      "epoch 19, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3800\n",
      "epoch 20, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  3900\n",
      "training @ iter =  4000\n",
      "epoch 21, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  4100\n",
      "training @ iter =  4200\n",
      "epoch 22, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  4300\n",
      "training @ iter =  4400\n",
      "epoch 23, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  4500\n",
      "training @ iter =  4600\n",
      "epoch 24, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  4700\n",
      "training @ iter =  4800\n",
      "epoch 25, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  4900\n",
      "training @ iter =  5000\n",
      "epoch 26, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  5100\n",
      "training @ iter =  5200\n",
      "epoch 27, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  5300\n",
      "training @ iter =  5400\n",
      "epoch 28, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  5500\n",
      "training @ iter =  5600\n",
      "epoch 29, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  5700\n",
      "training @ iter =  5800\n",
      "epoch 30, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  5900\n",
      "training @ iter =  6000\n",
      "epoch 31, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  6100\n",
      "training @ iter =  6200\n",
      "epoch 32, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  6300\n",
      "training @ iter =  6400\n",
      "epoch 33, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  6500\n",
      "training @ iter =  6600\n",
      "epoch 34, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  6700\n",
      "training @ iter =  6800\n",
      "epoch 35, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  6900\n",
      "training @ iter =  7000\n",
      "epoch 36, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  7100\n",
      "training @ iter =  7200\n",
      "epoch 37, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  7300\n",
      "training @ iter =  7400\n",
      "epoch 38, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  7500\n",
      "training @ iter =  7600\n",
      "epoch 39, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  7700\n",
      "epoch 40, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  7800\n",
      "training @ iter =  7900\n",
      "epoch 41, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  8000\n",
      "training @ iter =  8100\n",
      "epoch 42, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  8200\n",
      "training @ iter =  8300\n",
      "epoch 43, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  8400\n",
      "training @ iter =  8500\n",
      "epoch 44, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  8600\n",
      "training @ iter =  8700\n",
      "epoch 45, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  8800\n",
      "training @ iter =  8900\n",
      "epoch 46, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  9000\n",
      "training @ iter =  9100\n",
      "epoch 47, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  9200\n",
      "training @ iter =  9300\n",
      "epoch 48, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  9400\n",
      "training @ iter =  9500\n",
      "epoch 49, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  9600\n",
      "training @ iter =  9700\n",
      "epoch 50, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  9800\n",
      "training @ iter =  9900\n",
      "epoch 51, minibatch 195/195, validation error 75.223214 %\n",
      "training @ iter =  10000\n",
      "Optimization complete.\n",
      "Best validation score of 75.223214 % obtained at iteration 195, with test performance 75.055804 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a301b4a17ceb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_lenet5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.09\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-44db180777e5>\u001b[0m in \u001b[0;36mevaluate_lenet5\u001b[1;34m(learning_rate, n_epochs, dataset, nkerns, batch_size)\u001b[0m\n\u001b[0;32m    256\u001b[0m           (best_validation_loss * 100., best_iter + 1, test_score * 100.))\n\u001b[0;32m    257\u001b[0m     print >> sys.stderr, ('The code for file ' +\n\u001b[1;32m--> 258\u001b[1;33m                           \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m                           ' ran for %.2fm' % ((end_time - start_time) / 60.))\n",
      "\u001b[1;31mNameError\u001b[0m: global name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_lenet5(0.09, dataset=datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
