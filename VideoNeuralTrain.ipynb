{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 750M (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle \n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data set for facial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(23455)\n",
    "#load Facial expression dataset\n",
    "dataset = pd.read_csv('fer2013.csv')\n",
    "#print dataset.values\n",
    "# instantiate 4D tensor for input\n",
    "input = T.tensor4(name='input')\n",
    "srng = RandomStreams()\n",
    "#print dataset.values[0]\n",
    "#print np.__path__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01) , borrow=True)\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    return T.nnet.softmax(X)\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def oneHotExpression(num):\n",
    "    Y = np.zeros((1,7), dtype=np.int)\n",
    "    Y[0][num]= 1;\n",
    "    return Y\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w, w2, w3, w4, p_drop_conv, p_drop_hidden):\n",
    "    l1a = rectify(conv2d(X, w, border_mode='full'))\n",
    "    l1 = max_pool_2d(l1a, (2, 2))\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    l2a = rectify(conv2d(l1, w2))\n",
    "    l2 = max_pool_2d(l2a, (2, 2))\n",
    "    l2 = dropout(l2, p_drop_conv)\n",
    "\n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    l3b = max_pool_2d(l3a, (2, 2))\n",
    "    l3 = T.flatten(l3b, outdim=2)\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "\n",
    "    l4 = rectify(T.dot(l3, w4))\n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "\n",
    "    pyx = softmax(T.dot(l4, w_o))\n",
    "    return l1 , l2 , l3 , l4, pyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define symbolic expression of training and optimisation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: max_pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=False is needed to use CuDNN. When using ignore_border=False and not using CuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "  app.launch_new_instance()\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: max_pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=False is needed to use CuDNN. When using ignore_border=False and not using CuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: max_pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=False is needed to use CuDNN. When using ignore_border=False and not using CuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n"
     ]
    }
   ],
   "source": [
    "X = T.ftensor4('X')\n",
    "Y = T.fmatrix('Y')\n",
    "\n",
    "w = init_weights((32, 1, 3, 3))\n",
    "w2 = init_weights((64, 32, 3, 3))\n",
    "w3 = init_weights((128, 64, 3, 3))\n",
    "w4 = init_weights((128 * 3 * 3, 625))\n",
    "w_o = init_weights((625, 10))\n",
    "\n",
    "noise_l1, noise_l2, noise_l3, noise_l4, noise_py_x = model(X, w, w2, w3, w4, 0.2, 0.5)\n",
    "l1, l2, l3, l4, py_x = model(X, w, w2, w3, w4, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w, w2, w3, w4, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "#print np.asarray(dataset.values[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GpuCorrMM encountered a CUDA error in im2col: unspecified launch failure\nThis could be a known bug in CUDA, please see the GpuCorrMM() documentation.\n\nApply node that caused the error: GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)\nToposort index: 73\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]\nInputs shapes: [(1, 32, 25, 25), (64, 32, 3, 3)]\nInputs strides: [(0, 625, 25, 1), (288, 9, 3, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{maximum,no_inplace}(GpuCorrMM{valid, (1, 1)}.0, CudaNdarrayConstant{error while transferring the value: error (unspecified launch failure)copying data to host}), GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 0)](GpuElemwise{maximum,no_inplace}.0, GpuCorrMM{valid, (1, 1)}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-58d3a405dc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moneHotExpression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#print np.mean(np.argmax(teY, axis=1) == predict(teX))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GpuCorrMM encountered a CUDA error in im2col: unspecified launch failure\nThis could be a known bug in CUDA, please see the GpuCorrMM() documentation.\n\nApply node that caused the error: GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)\nToposort index: 73\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]\nInputs shapes: [(1, 32, 25, 25), (64, 32, 3, 3)]\nInputs strides: [(0, 625, 25, 1), (288, 9, 3, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{maximum,no_inplace}(GpuCorrMM{valid, (1, 1)}.0, CudaNdarrayConstant{error while transferring the value: error (unspecified launch failure)copying data to host}), GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 0)](GpuElemwise{maximum,no_inplace}.0, GpuCorrMM{valid, (1, 1)}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "for i in range(3000):\n",
    "    trX = np.asarray(dataset.values[i][1].split(\" \") , dtype=\"float64\")\n",
    "    trX = trX.reshape(-1, 1, 48, 48)\n",
    "    trY = np.asarray(dataset.values[i][0])\n",
    "    trY = oneHotExpression(trY)\n",
    "    cost = train(trX, trY)\n",
    "#print np.mean(np.argmax(teY, axis=1) == predict(teX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
