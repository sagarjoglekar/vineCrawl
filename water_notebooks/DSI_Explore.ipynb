{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from contextlib import closing\n",
    "from xml.etree import ElementTree as etree\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from contextlib import closing\n",
    "from xml.etree import ElementTree as etree\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from six.moves import cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_dataset = \"/datasets/dk/news-short-2015-2\"\n",
    "\n",
    "keywords = [\"farmers\",\"draught\",\"water scarcity\",\"drought\",\"hosepipe ban\",\"water scarcity\",\"water conservation\",\n",
    "            \"water crisis\" , \"water resilience\" , \"water reuse\" , \"shower ban\", \"water use\",\"water consumption\"\n",
    "            \"water saving\" , \"shower\" ,\"shower less\", \"less water\", \"bathing less\",\"irrigation\" , \"crop yield\" ,\n",
    "            \"dry shampoo\", \"grey water\", \"bathing wipes\" ,\"farmer issues\" , \"lower yield\",\"crops\" ,\"hot summer\",\n",
    "            \"scorching\" , \"heat wave\", \"water cuts\" , \"watercuts\" , \"water shortage\" , \"dry summer\", \"hot weather\", \n",
    "            \"picnic weather\", \"beach weather\",\"blocking\", \"blocking anticyclone\", \"anticyclone\" , \"el nino\",\n",
    "            \"El Nino\", \"La Nina\"]\n",
    "total = 0\n",
    "finalData = \"/datasets/sagarj/water_scarcity/waterNewsDataMatched_2015_2.pkl\"\n",
    "curatedData = []\n",
    "\n",
    "currentDir =  os.getcwd();\n",
    "logPickle = currentDir + \"/curationMatched_2015_2.pk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def walkLevel1Dir(root):\n",
    "    count = 0\n",
    "    dirList = []\n",
    "    filesList = []\n",
    "    for path, dirs, files in os.walk(root):\n",
    "        print path\n",
    "        if count > 0:\n",
    "            return dirList , fileList\n",
    "        dirList = dirs\n",
    "        fileList = files\n",
    "        count = count + 1\n",
    "        \n",
    "def walkDir(root):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(root):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_big = walkDir(news_dataset)\n",
    "files = []\n",
    "for i in range(len(files_big)):\n",
    "    if i%8 == 0:\n",
    "        files.append(files_big[i])\n",
    "#print files\n",
    "total = float(len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-05-08T21-07-23Z.xml.gz\n",
      "Progress 0.007955 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-17T08-32-21Z.xml.gz\n",
      "Progress 0.015911 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-01T17-03-52Z.xml.gz\n",
      "Progress 0.023866 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-07-12T18-27-44Z.xml.gz\n",
      "Progress 0.031822 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-05-15T17-17-45Z.xml.gz\n",
      "Progress 0.039777 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-04-02T12-52-28Z.xml.gz\n",
      "Progress 0.047733 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-04-21T17-45-02Z.xml.gz\n",
      "Progress 0.055688 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-10T16-39-07Z.xml.gz\n",
      "Progress 0.063644 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-05-11T17-59-16Z.xml.gz\n",
      "Progress 0.071599 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-04-10T06-05-40Z.xml.gz\n",
      "Progress 0.079554 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-04-21T10-15-41Z.xml.gz\n",
      "Progress 0.087510 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-07-01T10-45-05Z.xml.gz\n",
      "Progress 0.095465 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-05-02T17-20-28Z.xml.gz\n",
      "Progress 0.103421 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-19T10-24-50Z.xml.gz\n",
      "Progress 0.111376 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-01T07-22-32Z.xml.gz\n",
      "Progress 0.119332 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-29T17-46-08Z.xml.gz\n",
      "Progress 0.127287 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-01T11-59-30Z.xml.gz\n",
      "Progress 0.135243 percent\n",
      "Parsing /datasets/dk/news-short-2015-2/public-news-2015-06-26T09-44-14Z.xml.gz\n",
      "Progress 0.143198 percent"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "for f in files:\n",
    "    path = news_dataset + \"/\" + f\n",
    "    print \"Parsing %s\" % path\n",
    "    \n",
    "    with gzip.open(path) as archive:\n",
    "        articles = []\n",
    "        fdata=archive.read()\n",
    "        xmldata=BeautifulSoup(fdata)\n",
    "        articles =  xmldata.html.body.findAll('article')\n",
    "        \n",
    "        for article in articles:\n",
    "            line =  article.find('body-cleartext').text\n",
    "            matched = 0\n",
    "            matched_strings=[]\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                if(line.find(keyword) > 0):\n",
    "                    matched = matched + 1\n",
    "                    matched_strings.append(keyword)\n",
    "            \n",
    "            if (matched > 0):\n",
    "                country = \"\"\n",
    "                lat = \"\"\n",
    "                log = \"\"\n",
    "                if article.location is not None and article.location.country is not None  : \n",
    "                    country = article.location.country.text\n",
    "                if article.location is not None and article.location.latitude is not None:\n",
    "                    lat = article.location.latitude.text\n",
    "                if article.location is not None and article.location.longitude is not None :\n",
    "                    log = article.location.longitude.text\n",
    "                \n",
    "                data={\n",
    "                    'country' :  country ,\n",
    "                    'latitude' : lat ,\n",
    "                    'longitude' : log ,\n",
    "                    'timeStamp' : article.find('retrieved-date').text ,\n",
    "                    'text' : line,\n",
    "                    'matched' : matched_strings\n",
    "                    }\n",
    "                curatedData.append(data)\n",
    "    \n",
    "    count = count + 1\n",
    "    done = (count/total) * 100\n",
    "    logline = \"Progress %f percent\"%(done)\n",
    "    print logline\n",
    "    flog = open(logPickle, 'a+')\n",
    "    cPickle.dump(logline , flog);\n",
    "    flog.close()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(finalData, 'a+')\n",
    "cPickle.dump(curatedData, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "with open('data_2.p', 'wb') as fp:\n",
    "    pickle.dump(curatedData, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('curated_2.json', 'w') as fp:\n",
    "    json.dump(curatedData, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
